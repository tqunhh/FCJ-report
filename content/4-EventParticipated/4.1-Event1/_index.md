---
title: "Event 1"
date: "2025-01-01"
weight: 1
chapter: false
pre: " <b> 4.1. </b> "
---


# Takeaways from "AI/ML/GenAI on AWS Workshop"

### Event Purpose

- Provide an overview of the AI/ML ecosystem on AWS
- Introduce Amazon SageMaker – end-to-end ML platform
- Explore Generative AI with Amazon Bedrock
- Hands-on building GenAI Chatbot
- Get familiar with Prompt Engineering, RAG, Bedrock Agents & Guardrails
- Connect with the AI/ML community in Vietnam

### Speaker List

- **Lam Tuan Kiet** - Senior DevOps Engineer, FPT Software
- **Danh Hoang Hieu Nghi** - AI Engineer, Renova Cloud
- **Dinh Le Hoang Anh** - Cloud Engineer Trainee, First Cloud AI Journey

### Highlighted Content

#### AWS AI/ML Services Overview

Attendees were introduced to the overall picture of AI/ML services on AWS, from data preparation, training, deployment to monitoring and automation.

#### Amazon SageMaker – End-to-End ML Platform

* Data preparation & labeling
* Model training, hyperparameter tuning
* Deployment strategies and best practices
* MLOps integration (CI/CD, pipeline, monitoring)

 **Live Demo**: SageMaker Studio walkthrough helps visualize ML workflow from A → Z in a real environment.

#### Generative AI with Amazon Bedrock

**Foundation Models**
 * Comparison and guidance on choosing between Claude, Llama, Titan
 * Clearly understand strengths and weaknesses according to each use case

**RAG (Retrieval-Augmented Generation)**
 * Overall architecture of RAG system
 * How to integrate Knowledge Base with LLM
 * RAG use cases in enterprises (internal search, support chatbot, QA system)

#### Bedrock Agents & Guardrails


* Build multi-step workflows
* Integrate tools, APIs
* Set up safety & content filtering to ensure safe and compliant AI

**Live Demo**: Building Generative AI Chatbot using Amazon Bedrock + RAG – an extremely impressive highlight of the workshop.

### What I Learned
 After the workshop, I gained: 
#### Amazon SageMaker

* Clearly understand end-to-end ML on AWS
* Grasp the training, tuning & deployment process
* Visualize MLOps workflow and automation methods

#### Generative AI with Amazon Bedrock

* How to choose appropriate Foundation Model
* Apply Prompt Engineering for LLM
* Understand the essence of Chain-of-Thought & Few-shot learning

#### RAG

* How LLM combines with internal data
* RAG applications in enterprise AI systems

### Bedrock Agents & Guardrails

* Multi-step orchestration with AI Agents
* Ensure safety, control generated content

### Hands-on Experience

* Practice with SageMaker Studio
* Build real GenAI chatbot

### Event Experience

Participating in the **"AI/ML/GenAI on AWS"** workshop was a valuable experience, helping me expand my perspective on how AWS is supporting the building and operation of AI/ML systems, especially Generative AI, in modern cloud environments. The event was not only technical but also clearly conveyed the mindset of deploying AI into real-world problems.

#### Learning from highly specialized speakers
- The speakers all came from teams with experience deploying **AI/ML** in production environments. Instead of just talking about theory, they focused on sharing real scenarios, lessons learned when building, operating and scaling AI systems on AWS.

- Through the presentations, I better understood the role of architecture, security and automation in bringing ML models from the experimental stage to stable operation.

#### Practical technical experience
- The presentation sessions helped me visualize the entire lifecycle of an ML system:
  * From data preparation, training and tuning models
  * To deployment and monitoring in cloud environment
- Additionally, the introduction to Generative AI provided a new perspective on how to combine Foundation Models with internal data, thereby creating intelligent applications capable of responding closely to business context.
#### Modern tool application
- The workshop was an opportunity to directly learn about AWS AI/ML services:
  * Amazon SageMaker simplifies the entire ML workflow
  * Amazon Bedrock opens up the ability to build GenAI applications without managing complex infrastructure
- Through the demos, I realized that leveraging managed services helps technical teams focus more on logic and business value, rather than dealing with infrastructure issues.

#### Connection and exchange
- The event created an open space for exchange between cloud, AI, DevOps practitioners and those in the learning phase. Sharing perspectives from different roles helped me understand that a successful AI system depends not only on the model but also on how the team coordinates and deploys.
- Side conversations brought more practical perspectives on learning and development paths in the AI/ML field on AWS.
#### Lessons learned
- AI/ML and Generative AI only truly deliver value when placed in the context of specific problems
- Choosing appropriate services and models is as important as building the model
- Managed services on AWS significantly reduce barriers to deploying AI at scale
- Learning combined with practice is the fastest way to master new technology

